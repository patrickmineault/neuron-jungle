{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import dask\n",
    "import gcsfs\n",
    "import h5py\n",
    "import io\n",
    "import numba\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path\n",
    "import pickle\n",
    "import requests\n",
    "\n",
    "from dask.distributed import Client\n",
    "from dask_kubernetes import KubeCluster\n",
    "from numba.typed import Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Clear task state\n",
      "distributed.scheduler - INFO -   Scheduler at:   tcp://10.36.0.109:34455\n",
      "distributed.scheduler - INFO -   dashboard at:                     :8787\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e184b142edb448ba906ec18be9638c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>KubeCluster</h2>'), HBox(children=(HTML(value='\\n<div>\\n  <style scoped>\\n    .â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cluster = KubeCluster.from_yaml('worker-spec.yml')\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Receive client connection: Client-90270908-43c4-11ea-804c-16c367d7eede\n",
      "distributed.core - INFO - Starting established connection\n"
     ]
    }
   ],
   "source": [
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the client is working well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@dask.delayed\n",
    "def the_sum(a, b):\n",
    "    return a + b\n",
    "the_sum(the_sum(1, 2), 3).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('../../.gcs_tokens'):\n",
    "    # Get a token\n",
    "    gcsfs.GCSFileSystem(project='neuron-jungle', token='browser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['l4dense/segmentation-volume/x1y4z1.hdf5',\n",
       " 'l4dense/segmentation-volume/x0y2z0.hdf5',\n",
       " 'l4dense/segmentation-volume/x3y0z0.hdf5',\n",
       " 'l4dense/segmentation-volume/x4y7z3.hdf5',\n",
       " 'l4dense/segmentation-volume/x4y2z2.hdf5',\n",
       " 'l4dense/segmentation-volume/x5y7z1.hdf5',\n",
       " 'l4dense/segmentation-volume/x0y5z3.hdf5',\n",
       " 'l4dense/segmentation-volume/x2y1z1.hdf5',\n",
       " 'l4dense/segmentation-volume/x5y8z2.hdf5',\n",
       " 'l4dense/segmentation-volume/x2y0z0.hdf5']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../.gcs_tokens', 'rb') as f:\n",
    "    credentials = pickle.load(f)\n",
    "credentials = credentials[list(credentials.keys())[0]]\n",
    "fs = gcsfs.GCSFileSystem(project='neuron-jungle', token=credentials)\n",
    "fs.ls('l4dense/segmentation-volume')[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a map from segment id to neuron id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "318936822"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def download(filename):\n",
    "    url = f\"https://l4dense2019.brain.mpg.de/webdav/{filename}\"\n",
    "    result = requests.get(url, verify=False)\n",
    "    result.raise_for_status()\n",
    "    return result.content\n",
    "\n",
    "def upload(filename, data, credentials):\n",
    "    fs = gcsfs.GCSFileSystem(project='neuron-jungle', token=credentials)\n",
    "    with fs.open(f'l4dense/{filename}', 'wb') as f:\n",
    "        num_bytes = f.write(data)\n",
    "    return num_bytes\n",
    "\n",
    "def mirror(filename):\n",
    "    print(f\"Fetching {filename}\")\n",
    "    data = download(filename)\n",
    "    num_bytes = upload(filename, data, credentials)\n",
    "    return num_bytes\n",
    "\n",
    "\n",
    "def locally_cache(filename, credentials):\n",
    "    fs = gcsfs.GCSFileSystem(project='neuron-jungle', token=credentials)\n",
    "    with fs.open(f'l4dense/{filename}', 'rb') as f:\n",
    "        data = f.read()\n",
    "    with open(f'../cache/{filename}', 'wb') as f:\n",
    "        f.write(data)\n",
    "    return len(data)\n",
    "\n",
    "mirror('axons.hdf5')\n",
    "locally_cache('dendrites.hdf5', credentials)\n",
    "locally_cache('axons.hdf5', credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "dendrites = h5py.File('../cache/dendrites.hdf5', 'r')\n",
    "axons = h5py.File('../cache/axons.hdf5', 'r')\n",
    "\n",
    "# Build a map from agglomerate ID to neuron id\n",
    "agg_to_neuron_id = {k: v for k, v in zip(list(dendrites['dendrites']['agglomerate']), list(dendrites['dendrites']['neuronId']))}\n",
    "\n",
    "d = collections.defaultdict(lambda: [])\n",
    "for agg in list(dendrites['dendrites']['agglomerate'].keys()):\n",
    "    if agg in agg_to_neuron_id and agg_to_neuron_id[agg] > 0:\n",
    "        id = agg_to_neuron_id[agg]\n",
    "        d[id] += list(dendrites['dendrites']['agglomerate'][agg])\n",
    "        \n",
    "# Also add the axons for these neurons.\n",
    "in_map = 0\n",
    "for agg in list(axons['axons']['agglomerate'].keys()):\n",
    "    # Find the neuron id for this one.\n",
    "    if agg in agg_to_neuron_id:\n",
    "        in_map += 1\n",
    "    if agg in agg_to_neuron_id and agg_to_neuron_id[agg] > 0:\n",
    "        id = agg_to_neuron_id[agg]\n",
    "        d[id] += list(axons['axons']['agglomerate'][agg])\n",
    "        \n",
    "neuron_map = {}\n",
    "for neuron_id, segment_ids in d.items():\n",
    "    for segment_id in segment_ids:\n",
    "        neuron_map[segment_id] = neuron_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save it to GCS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = gcsfs.GCSFileSystem(project='neuron-jungle', token=credentials)\n",
    "with fs.open('l4dense/neuron-map-with-axons.pkl', 'wb') as f:\n",
    "    f.write(pickle.dumps(neuron_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit(nopython=True)\n",
    "def remap(data, the_map):\n",
    "    b = np.zeros_like(data)\n",
    "    c = {}\n",
    "    for i in range(len(data)):\n",
    "        if data[i] in the_map:\n",
    "            b[i] = the_map[data[i]]\n",
    "            c[the_map[data[i]]] = 1\n",
    "    return b, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To repaint: map dendrite ids to neuron id (default to 0)\n",
    "from scipy.ndimage import morphology\n",
    "\n",
    "@dask.delayed\n",
    "def repaint(filename, credentials):    \n",
    "    # Create a typed map for segment_to_neuron\n",
    "    fs = gcsfs.GCSFileSystem(project='neuron-jungle', token=credentials)\n",
    "    with fs.open('l4dense/neuron-map.pkl', 'rb') as f:\n",
    "        segment_to_neuron = pickle.loads(f.read())\n",
    "\n",
    "    the_map_typed = Dict.empty(key_type=numba.int32, value_type=numba.uint8)\n",
    "    for k, v in segment_to_neuron.items():\n",
    "        the_map_typed[k] = v\n",
    "    \n",
    "    neuron_ids = set()\n",
    "    with fs.open(f'l4dense/segmentation-volume/{filename}', 'rb') as f:    \n",
    "        cube = h5py.File(f, 'r')\n",
    "        \n",
    "        a = np.zeros((1024, 1024, 1024), dtype=np.uint8)\n",
    "        \n",
    "        slice_size = 32\n",
    "        nslices = int(1024 / slice_size)\n",
    "        \n",
    "        for j in range(nslices):\n",
    "            subd = np.array(cube['data'][(slice_size*j):(slice_size*(j+1)), :, :])\n",
    "            for i in range(nslices):\n",
    "                r, neuron_id = remap(subd[i, :, :].ravel(), the_map_typed)\n",
    "                a[i + j*slice_size, :, :] = r.astype(np.uint8).reshape((1024, 1024))\n",
    "                neuron_ids = neuron_ids.union(set(neuron_id.keys()))\n",
    "    \n",
    "    neuron_ids = np.array(list(neuron_ids))\n",
    "    \n",
    "    # Do some signal processing on each of the neurons\n",
    "    #a_processed = np.zeros((1024, 1024, 1024), dtype=np.uint8)\n",
    "    #for neuron_id in neuron_ids:\n",
    "    #    B = (a == neuron_id)\n",
    "    #    B = morphology.binary_erosion(morphology.binary_fill_holes(morphology.binary_dilation(B, iterations=3)), iterations=2)\n",
    "    #    a_processed[B] = neuron_id\n",
    "    \n",
    "    #del a\n",
    "    \n",
    "    bio = io.BytesIO()\n",
    "    cube = h5py.File(bio, 'w')\n",
    "    cube.create_dataset('data', a_processed.shape, compression=\"gzip\", data=a_processed)\n",
    "    cube.create_dataset('neuron_ids', neuron_ids.shape, data=neuron_ids)\n",
    "    cube.close()\n",
    "\n",
    "    data = bio.getvalue()\n",
    "    with fs.open(f'l4dense/neuron-volume-with-axons/{filename}', 'wb') as f:\n",
    "        f.write(data)\n",
    "    return len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n",
      "0 0 1\n",
      "0 0 2\n",
      "0 0 3\n",
      "0 1 0\n",
      "0 1 1\n",
      "0 1 2\n",
      "0 1 3\n",
      "0 2 0\n",
      "0 2 1\n",
      "0 2 2\n",
      "0 2 3\n",
      "0 3 0\n",
      "0 3 1\n",
      "0 3 2\n",
      "0 3 3\n",
      "0 4 0\n",
      "0 4 1\n",
      "0 4 2\n",
      "0 4 3\n",
      "0 5 0\n",
      "0 5 1\n",
      "0 5 2\n",
      "0 5 3\n",
      "0 6 0\n",
      "0 6 1\n",
      "0 6 2\n",
      "0 6 3\n",
      "0 7 0\n",
      "0 7 1\n",
      "0 7 2\n",
      "0 7 3\n",
      "0 8 0\n",
      "0 8 1\n",
      "0 8 2\n",
      "0 8 3\n",
      "1 0 0\n",
      "1 0 1\n",
      "1 0 2\n",
      "1 0 3\n",
      "1 1 0\n",
      "1 1 1\n",
      "1 1 2\n",
      "1 1 3\n",
      "1 2 0\n",
      "1 2 1\n",
      "1 2 2\n",
      "1 2 3\n",
      "1 3 0\n",
      "1 3 1\n",
      "1 3 2\n",
      "1 3 3\n",
      "1 4 0\n",
      "1 4 1\n",
      "1 4 2\n",
      "1 4 3\n",
      "1 5 0\n",
      "1 5 1\n",
      "1 5 2\n",
      "1 5 3\n",
      "1 6 0\n",
      "1 6 1\n",
      "1 6 2\n",
      "1 6 3\n",
      "1 7 0\n",
      "1 7 1\n",
      "1 7 2\n",
      "1 7 3\n",
      "1 8 0\n",
      "1 8 1\n",
      "1 8 2\n",
      "1 8 3\n",
      "2 0 0\n",
      "2 0 1\n",
      "2 0 2\n",
      "2 0 3\n",
      "2 1 0\n",
      "2 1 1\n",
      "2 1 2\n",
      "2 1 3\n",
      "2 2 0\n",
      "2 2 1\n",
      "2 2 2\n",
      "2 2 3\n",
      "2 3 0\n",
      "2 3 1\n",
      "2 3 2\n",
      "2 3 3\n",
      "2 4 0\n",
      "2 4 1\n",
      "2 4 2\n",
      "2 4 3\n",
      "2 5 0\n",
      "2 5 1\n",
      "2 5 2\n",
      "2 5 3\n",
      "2 6 0\n",
      "2 6 1\n",
      "2 6 2\n",
      "2 6 3\n",
      "2 7 0\n",
      "2 7 1\n",
      "2 7 2\n",
      "2 7 3\n",
      "2 8 0\n",
      "2 8 1\n",
      "2 8 2\n",
      "2 8 3\n",
      "3 0 0\n",
      "3 0 1\n",
      "3 0 2\n",
      "3 0 3\n",
      "3 1 0\n",
      "3 1 1\n",
      "3 1 2\n",
      "3 1 3\n",
      "3 2 0\n",
      "3 2 1\n",
      "3 2 2\n",
      "3 2 3\n",
      "3 3 0\n",
      "3 3 1\n",
      "3 3 2\n",
      "3 3 3\n",
      "3 4 0\n",
      "3 4 1\n",
      "3 4 2\n",
      "3 4 3\n",
      "3 5 0\n",
      "3 5 1\n",
      "3 5 2\n",
      "3 5 3\n",
      "3 6 0\n",
      "3 6 1\n",
      "3 6 2\n",
      "3 6 3\n",
      "3 7 0\n",
      "3 7 1\n",
      "3 7 2\n",
      "3 7 3\n",
      "3 8 0\n",
      "3 8 1\n",
      "3 8 2\n",
      "3 8 3\n",
      "4 0 0\n",
      "4 0 1\n",
      "4 0 2\n",
      "4 0 3\n",
      "4 1 0\n",
      "4 1 1\n",
      "4 1 2\n",
      "4 1 3\n",
      "4 2 0\n",
      "4 2 1\n",
      "4 2 2\n",
      "4 2 3\n",
      "4 3 0\n",
      "4 3 1\n",
      "4 3 2\n",
      "4 3 3\n",
      "4 4 0\n",
      "4 4 1\n",
      "4 4 2\n",
      "4 4 3\n",
      "4 5 0\n",
      "4 5 1\n",
      "4 5 2\n",
      "4 5 3\n",
      "4 6 0\n",
      "4 6 1\n",
      "4 6 2\n",
      "4 6 3\n",
      "4 7 0\n",
      "4 7 1\n",
      "4 7 2\n",
      "4 7 3\n",
      "4 8 0\n",
      "4 8 1\n",
      "4 8 2\n",
      "4 8 3\n",
      "5 0 0\n",
      "5 0 1\n",
      "5 0 2\n",
      "5 0 3\n",
      "5 1 0\n",
      "5 1 1\n",
      "5 1 2\n",
      "5 1 3\n",
      "5 2 0\n",
      "5 2 1\n",
      "5 2 2\n",
      "5 2 3\n",
      "5 3 0\n",
      "5 3 1\n",
      "5 3 2\n",
      "5 3 3\n",
      "5 4 0\n",
      "5 4 1\n",
      "5 4 2\n",
      "5 4 3\n",
      "5 5 0\n",
      "5 5 1\n",
      "5 5 2\n",
      "5 5 3\n",
      "5 6 0\n",
      "5 6 1\n",
      "5 6 2\n",
      "5 6 3\n",
      "5 7 0\n",
      "5 7 1\n",
      "5 7 2\n",
      "5 7 3\n",
      "5 8 0\n",
      "5 8 1\n",
      "5 8 2\n",
      "5 8 3\n"
     ]
    }
   ],
   "source": [
    "# x5y8z3 are the largest ids\n",
    "bytes_total = 0\n",
    "for i in range(6):\n",
    "    for j in range(9):\n",
    "        for k in range(4):\n",
    "            print(i, j, k)\n",
    "            bytes_total += repaint(f\"x{i}y{j}z{k}.hdf5\", credentials)\n",
    "bytes_total.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
