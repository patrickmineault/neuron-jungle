{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import dask\n",
    "import gcsfs\n",
    "import h5py\n",
    "import io\n",
    "import numba\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path\n",
    "import pickle\n",
    "import requests\n",
    "\n",
    "from dask.distributed import Client\n",
    "from dask_kubernetes import KubeCluster\n",
    "from numba.typed import Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Clear task state\n",
      "distributed.scheduler - INFO -   Scheduler at:    tcp://10.36.0.37:42901\n",
      "distributed.scheduler - INFO -   dashboard at:                     :8787\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb6284732e2846a58aae2e166a314b7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>KubeCluster</h2>'), HBox(children=(HTML(value='\\n<div>\\n  <style scoped>\\n    .â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cluster = KubeCluster.from_yaml('worker-spec.yml')\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Receive client connection: Client-8acd23e8-389d-11ea-810f-26996f775df6\n",
      "distributed.core - INFO - Starting established connection\n"
     ]
    }
   ],
   "source": [
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the client is working well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@dask.delayed\n",
    "def the_sum(a, b):\n",
    "    return a + b\n",
    "the_sum(the_sum(1, 2), 3).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('../../.gcs_tokens'):\n",
    "    # Get a token\n",
    "    gcsfs.GCSFileSystem(project='neuron-jungle', token='browser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['l4dense/segmentation-volume/x3y8z3.hdf5',\n",
       " 'l4dense/segmentation-volume/x2y6z3.hdf5',\n",
       " 'l4dense/segmentation-volume/x5y2z1.hdf5',\n",
       " 'l4dense/segmentation-volume/x3y4z0.hdf5',\n",
       " 'l4dense/segmentation-volume/x3y8z2.hdf5',\n",
       " 'l4dense/segmentation-volume/x3y4z2.hdf5',\n",
       " 'l4dense/segmentation-volume/x4y1z2.hdf5',\n",
       " 'l4dense/segmentation-volume/x0y5z3.hdf5',\n",
       " 'l4dense/segmentation-volume/x3y2z2.hdf5',\n",
       " 'l4dense/segmentation-volume/x0y3z2.hdf5']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../.gcs_tokens', 'rb') as f:\n",
    "    credentials = pickle.load(f)\n",
    "credentials = credentials[list(credentials.keys())[0]]\n",
    "fs = gcsfs.GCSFileSystem(project='neuron-jungle', token=credentials)\n",
    "fs.ls('l4dense/segmentation-volume')[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a map from segment id to neuron id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263193540"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def locally_cache(filename, credentials):\n",
    "    fs = gcsfs.GCSFileSystem(project='neuron-jungle', token=credentials)\n",
    "    with fs.open(f'l4dense/{filename}', 'rb') as f:\n",
    "        data = f.read()\n",
    "    with open(f'../cache/{filename}', 'wb') as f:\n",
    "        f.write(data)\n",
    "    return len(data)\n",
    "\n",
    "locally_cache('dendrites.hdf5', credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 group \"/dendrites/agglomerate\" (11400 members)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dendrites['dendrites']['agglomerate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dendrites = h5py.File('../cache/dendrites.hdf5', 'r')\n",
    "\n",
    "d = collections.defaultdict(lambda: [])\n",
    "neuronId = np.array(dendrites['dendrites']['neuronId'])\n",
    "for i, id in enumerate(neuronId):\n",
    "    if id > 0:\n",
    "        # Append the dendrite ids to the right slot.\n",
    "        d[id] += np.array(dendrites['dendrites']['agglomerate'][str(i + 1)]).tolist()\n",
    "    \n",
    "neuron_map = {}\n",
    "for neuron_id, segment_ids in d.items():\n",
    "    for segment_id in segment_ids:\n",
    "        neuron_map[segment_id] = neuron_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit(nopython=True)\n",
    "def remap(data, the_map):\n",
    "    b = np.zeros_like(data)\n",
    "    for i in range(len(data)):\n",
    "        if data[i] in the_map:\n",
    "            b[i] = the_map[data[i]]\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To repaint: map dendrite ids to neuron id (default to 0)\n",
    "@dask.delayed\n",
    "def repaint(filename, credentials):    \n",
    "    # Create a typed map for segment_to_neuron\n",
    "    fs = gcsfs.GCSFileSystem(project='neuron-jungle', token=credentials)\n",
    "    with fs.open('l4dense/neuron-map.pkl', 'rb') as f:\n",
    "        segment_to_neuron = pickle.loads(f.read())\n",
    "\n",
    "    the_map_typed = Dict.empty(key_type=numba.int32, value_type=numba.uint8)\n",
    "    for k, v in segment_to_neuron.items():\n",
    "        the_map_typed[k] = v\n",
    "    \n",
    "    with fs.open(f'l4dense/segmentation-volume/{filename}', 'rb') as f:    \n",
    "        cube = h5py.File(f, 'r')\n",
    "        \n",
    "        a = np.zeros((1024, 1024, 1024), dtype=np.uint8)\n",
    "        \n",
    "        slice_size = 32\n",
    "        nslices = int(1024 / slice_size)\n",
    "        \n",
    "        for j in range(nslices):\n",
    "            subd = np.array(cube['data'][(slice_size*j):(slice_size*(j+1)), :, :])\n",
    "            for i in range(nslices):\n",
    "                a[i + j*slice_size, :, :] = remap(subd[i, :, :].ravel(), \n",
    "                                   the_map_typed).astype(np.uint8).reshape((1024, 1024))\n",
    "    \n",
    "    bio = io.BytesIO()\n",
    "    cube = h5py.File(bio, 'w')\n",
    "    cube.create_dataset('data', a.shape, compression=\"gzip\", data=a)\n",
    "    cube.close()\n",
    "\n",
    "    data = bio.getvalue()\n",
    "    with fs.open(f'l4dense/neuron-volume/{filename}', 'wb') as f:\n",
    "        f.write(data)\n",
    "    return len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = gcsfs.GCSFileSystem(project='neuron-jungle', token=credentials)\n",
    "with fs.open('l4dense/neuron-map.pkl', 'wb') as f:\n",
    "    f.write(pickle.dumps(neuron_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x5y8z3 are the largest ids\n",
    "bytes_total = 0\n",
    "for i in range(6):\n",
    "    for j in range(9):\n",
    "        for k in range(4):\n",
    "            print(i, j, k)\n",
    "            bytes_total += repaint(f\"x{i}y{j}z{k}.hdf5\", credentials)\n",
    "bytes_total.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = gcsfs.GCSFileSystem(project='neuron-jungle', token=credentials)\n",
    "with open('chunk_template.xdmf', 'r') as f:\n",
    "    data = f.read()\n",
    "    \n",
    "with fs.open('l4dense/chunk_template.xdmf', 'w') as f:\n",
    "    f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  7, 19, 20, 32, 33, 37, 38, 49, 53, 58, 68, 70, 79, 88, 89],\n",
       "      dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(data.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: gsutil: not found\n"
     ]
    }
   ],
   "source": [
    "!gsutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'vtkOpenGLKitPython'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/vtk/vtkOpenGLKit.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# use relative import for installed modules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvtkOpenGLKitPython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: libGL.so.1: cannot open shared object file: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-0ba68c7b7e5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mvtk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfetch_and_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcsfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGCSFileSystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neuron-jungle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/vtk/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvtkRenderingKit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvtkIOKit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvtkOpenGLKit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvtkParallelKit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvtkWrappingKit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/vtk/vtkOpenGLKit.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# during build and testing, the modules will be elsewhere,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# e.g. in lib directory or Release/Debug config directories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mvtkOpenGLKitPython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'vtkOpenGLKitPython'"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "import vtk\n",
    "\n",
    "def fetch_and_cache(filename, credentials, replacement=None):\n",
    "    fs = gcsfs.GCSFileSystem(project='neuron-jungle', token=credentials)\n",
    "    \n",
    "    if replacement is not None:\n",
    "        mode = 'r'\n",
    "    else:\n",
    "        mode = 'rb'\n",
    "    \n",
    "    with fs.open(f'l4dense/{filename}', mode) as f:\n",
    "        data = f.read()\n",
    "    \n",
    "    # Write this as a temp file.\n",
    "    _, filename = tempfile.mkstemp()\n",
    "    \n",
    "    if replacement is not None:\n",
    "        data = data.format(replacement)\n",
    "    \n",
    "    if replacement is not None:\n",
    "        mode = 'w'\n",
    "    else:\n",
    "        mode = 'wb'\n",
    "    \n",
    "    with open(filename, mode) as f:\n",
    "        f.write(data)\n",
    "    \n",
    "    return filename\n",
    "\n",
    "def process_one_chunk(filename, credentials):\n",
    "    index = 7\n",
    "    xdmf_file = \"chunk_template.xdmf\"\n",
    "    local_hdf_file = fetch_and_cache(filename, credentials)\n",
    "    local_xdmf = fetch_and_cache(xdmf_file, credentials, local_hdf_file)\n",
    "    \n",
    "    # Do the \n",
    "    colors = vtk.vtkNamedColors()\n",
    "\n",
    "    # Prepare to read the file.\n",
    "    readerVolume = vtk.vtkXdmfReader()\n",
    "    readerVolume.SetFileName(local_xdmf)\n",
    "    readerVolume.Update()\n",
    "\n",
    "    # Extract the region of interest.\n",
    "    voi = vtk.vtkExtractVOI()\n",
    "    voi.SetInputConnection(readerVolume.GetOutputPort())\n",
    "    voi.SetVOI(0, 1023, 0, 1023, 0, 1023)\n",
    "    voi.SetSampleRate(1, 1, 1)\n",
    "    voi.Update()  # Necessary for GetScalarRange().\n",
    "    srange = voi.GetOutput().GetScalarRange()  # Needs Update() before!\n",
    "    print(\"Range\", srange)\n",
    "\n",
    "    # Prepare surface generation.\n",
    "    contour = vtk.vtkDiscreteMarchingCubes()  # For label images.\n",
    "    contour.SetInputConnection(voi.GetOutputPort())\n",
    "    # contour.ComputeNormalsOn()\n",
    "\n",
    "    print(\"Doing label\", index)\n",
    "\n",
    "    contour.SetValue(0, index)\n",
    "    contour.Update()  # Needed for GetNumberOfPolys()!!!\n",
    "    \n",
    "    print(\"Done contour\")\n",
    "\n",
    "    smoother = vtk.vtkWindowedSincPolyDataFilter()\n",
    "    smoother.SetInputConnection(contour.GetOutputPort())\n",
    "    smoother.SetNumberOfIterations(20)  # This has little effect on the error!\n",
    "    smoother.BoundarySmoothingOff()\n",
    "    smoother.FeatureEdgeSmoothingOff()\n",
    "    smoother.SetPassBand(.001)        # This increases the error a lot!\n",
    "    smoother.NonManifoldSmoothingOn()\n",
    "    smoother.NormalizeCoordinatesOn()\n",
    "    smoother.GenerateErrorScalarsOn()\n",
    "    smoother.Update()\n",
    "\n",
    "    smoothed_polys = smoother.GetOutput()\n",
    "    smoother_error = smoothed_polys.GetPointData().GetScalars()\n",
    "\n",
    "    writer = vtk.vtkXMLDataSetWriter()\n",
    "    writer.SetFileName(\"out.vtp\")\n",
    "    writer.SetInputData(smoothed_polys)\n",
    "    writer.Write()\n",
    "    \n",
    "process_one_chunk('neuron-volume/x0y0z0.hdf5', credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
